# Machine learning notes

The below includes a curated list of useful resources related to professional development in Machine Learning and Data Science. Those include structured materials, MOOCs, YouTube videos, research papers, etc. I created this mostly to help organise my studies and understanding of the material.

All the contents belongs to the authors.


## Potential curriculuum:

**Methodology and practical applications**
  - Hypothesis space and Version Space
  - Model Selection
  - Variance and Bias Tradeoff
  - Train - test cycle
  - Validation and Cross-Validation
  - Detection of Errors
  - Design of Machine Learning applications
  
**Shallow Supervised Learning methods**
  - Logistic Regression
  - Regressions
  - Decision Trees
  - SVM
  - Instance-Based Learning
  - Bayesian Learning
   -Naive Bayes algorithm
   ..- [Domingos and Pazzani (1997). On the Optimality of the Simple Bayesian Classifier under Zero-One Loss](http://engr.case.edu/ray_soumya/mlrg/optimality_of_nb.pdf)
   ..- [H. Zhang (2004). The optimality of Naive Bayes]()
   ..- [Raschka (2014). Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329v4.pdf)
  - Bayesian Inference
  - Ensemble models (bagging, boosting)
  
**Unsupervised Learning**
  - Clustering
  - Feature Scaling
  
**Reinforcement Learning**
  - TBD
  
**Deep Learning**
  - Basic principles. Backpropagation
  - Feed-forward Neural Networks and Multilayer Perceptron
  - Autoencoders
  - CNNs
  - RNNs
  - LSTM

## Overview
* [Good overview of ML](http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/readings/week4/machine-learning-review-domingos.pdf)
* [Cheat Sheet: Algorithms for Supervised- and Unsupervised Learning (pdf)](http://eferm.com/wp-content/uploads/2011/05/cheat3.pdf)
* ["What are the most important ML algorithms" (Quora)](https://www.quora.com/What-are-the-most-important-Machine-Learning-algorithms/answer/Luis-Argerich?srid=nHw2)

---
### Explanation of algorithms
* [Naive Bayes explained](https://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/)
* [SVM - a guide to beginners](https://www.quantstart.com/articles/Support-Vector-Machines-A-Guide-for-Beginners)
* [Decision Trees (quite a bit actually - in pdf)](https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf)
* [Ensemble methods - Random Forests](https://citizennet.com/blog/2012/11/10/random-forests-ensembles-and-performance-metrics/)
* [Random Forests[Breiman 2001]](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)
* [k-Nearest Neighbour (part of CS231n intro lecture)](http://cs231n.github.io/classification/)

---
### Neural Networks & Deep Learning
Start with this amazing book (pdf on GitHub):
* [Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. "Deep learning." An MIT Press book. (2015)](https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf)

Great introduction using Keras:
* [François Chollet. "Deep Learning with Python" (2005)](https://www.manning.com/books/deep-learning-with-python)

Other materials and articles:
* [“Efficient BackProp” Y. LeCun, L. Bottou, G. Orr, K. Müller - In Neural Networks: Tricks of the Trade 1998.](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)
* [Neural Networks online book](http://neuralnetworksanddeeplearning.com/chap1.html)
* [Hacker's guide to Neural Networks (Andrej Karpathy / Python Walkthrough)](http://karpathy.github.io/neuralnets/)

CNNs
* [CS231n: Convolutional Neural Networks for Visual Recognition notes (Andrej Karpathy)](http://cs231n.github.io/convolutional-networks/)

RNNs & LSTM
* ["Training Recurrent Neural Networks" (I.Sutskever PhD thesis, pdf)](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)
* [The Unreasonable Effectiveness of Recurrent Neural Networks (Andrej Karpathy's blog)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [LSTM explained (colah.github.io.)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [LSTM for sentiment analysis](http://deeplearning.net/tutorial/lstm.html)

---
### GANs
* [GANs with TensorFlow](http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/)

---
### Hands on data / tutorials
* [Kaggle titanic competition tutorial using regression, SVM and random forest](http://nbviewer.jupyter.org/github/agconti/kaggle-titanic/blob/master/Titanic.ipynb)
* [Another one, really good](https://github.com/savarin/pyconuk-introtutorial)
* [MNIST for beginners in TensorFlow (hand-written digits recognition)](https://www.tensorflow.org/tutorials/mnist/beginners/)
* [Cool TensorFlow tutorials](https://github.com/aymericdamien/TensorFlow-Examples)

---
### Courses / structured materials
* [The open-source curriculum for learning Data Science](http://datasciencemasters.org)
* [Stanford's "Deep Learning for NLP" (CS224d)](http://cs224d.stanford.edu/syllabus.html)
* [Top-down learning path: Machine Learning for Software Engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers#kaggle-knowledge-competitions)
* [Amazing CS231n from Stanford feat. A Karpathy (video lectures)](https://www.youtube.com/playlist?list=PLlJy-eBtNFt6EuMxFYRiNRS07MCWN5UIA)
* [SciPy Lecture Notes](http://www.scipy-lectures.org/)
* [CSC321 - Introduction to Neural Networks and Machine Learning, Geoffrey Hinton - Winter 2014](http://www.cs.toronto.edu/~tijmen/csc321/)

---
### Blogs / resources to follow
* http://distill.pub/
* [Colah's blog](http://colah.github.io/)
* [OpenAI](https://openai.com/)
* [Berkelay AI Research blog](http://bair.berkeley.edu/blog/)
* [Data Science London](https://twitter.com/ds_ldn)
* [Montreal Institute for Learning Algorithms](https://mila.umontreal.ca/en/)

---
### Interesting stuff
* [Shane Legg's Thesis ("Machine Super Intelligence", pdf)](http://www.vetta.org/documents/Machine_Super_Intelligence.pdf)
* [Collection of cool Deep Learning projects](http://deeplearninggallery.com)
* [Machine Learning projects from Stanfrod CS229](http://cs229.stanford.edu/projects2013.html)
