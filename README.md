# Machine learning notes
Here I'll pin down some data analytics stuff which might or might not be useful. All the contents belongs to the authors.

## Overview
* [Good overview of ML](http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/readings/week4/machine-learning-review-domingos.pdf)
* [Cheat Sheet: Algorithms for Supervised- and Unsupervised Learning (pdf)](http://eferm.com/wp-content/uploads/2011/05/cheat3.pdf)
* ["What are the most important ML algorithms" (Quora)](https://www.quora.com/What-are-the-most-important-Machine-Learning-algorithms/answer/Luis-Argerich?srid=nHw2)

---
### Explanation of algorithms
* [Naive Bayes explained](https://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/)
* [SVM - a guide to beginners](https://www.quantstart.com/articles/Support-Vector-Machines-A-Guide-for-Beginners)
* [Decision Trees (quite a bit actually - in pdf)](https://www-users.cs.umn.edu/~kumar/dmbook/ch4.pdf)
* [Ensemble methods - Random Forests](https://citizennet.com/blog/2012/11/10/random-forests-ensembles-and-performance-metrics/)
* [k-Nearest Neighbour (part of CS231n intro lecture)](http://cs231n.github.io/classification/)

---
### Neural Networks & Deep Learning
Start w/ this amazing book:
* [Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. "Deep learning." An MIT Press book. (2015)](https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf)

Other materials and articles:
* [“Efficient BackProp” Y. LeCun, L. Bottou, G. Orr, K. Müller - In Neural Networks: Tricks of the Trade 1998.](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)
* [Neural Networks online book](http://neuralnetworksanddeeplearning.com/chap1.html)
* [Hacker's guide to Neural Networks (Andrej Karpathy / Python Walkthrough)](http://karpathy.github.io/neuralnets/)
CNNs
* [CS231n: Convolutional Neural Networks for Visual Recognition notes (Andrej Karpathy)](http://cs231n.github.io/convolutional-networks/)

RNNs & LSTM
* ["Training Recurrent Neural Networks" (I.Sutskever PhD thesis, pdf)](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)
* [The Unreasonable Effectiveness of Recurrent Neural Networks (Andrej Karpathy's blog)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [LSTM explained (colah.github.io.)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [LSTM for sentiment analysis](http://deeplearning.net/tutorial/lstm.html)

---
### GANs
* [GANs with TensorFlow](http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/)

---
### Hands on data / tutorials
* [Kaggle titanic competition tutorial using regression, SVM and random forest](http://nbviewer.jupyter.org/github/agconti/kaggle-titanic/blob/master/Titanic.ipynb)
* [Another one, really good](https://github.com/savarin/pyconuk-introtutorial)
* [MNIST for beginners in TensorFlow (hand-written digits recognition)](https://www.tensorflow.org/tutorials/mnist/beginners/)
* [Cool TensorFlow tutorials](https://github.com/aymericdamien/TensorFlow-Examples)

---
### Courses / structured materials
* [The open-source curriculum for learning Data Science](http://datasciencemasters.org)
* [Stanford's "Deep Learning for NLP" (CS224d)](http://cs224d.stanford.edu/syllabus.html)
* [Top-down learning path: Machine Learning for Software Engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers#kaggle-knowledge-competitions)
* [Amazing CS231n from Stanford feat. A Karpathy (video lectures)](https://www.youtube.com/playlist?list=PLlJy-eBtNFt6EuMxFYRiNRS07MCWN5UIA)

---
### Blogs / resources to follow
* http://distill.pub/
* [Colah's blog](http://colah.github.io/)
* [OpenAI](https://openai.com/)

---
### Interesting stuff
* [Shane Legg's Thesis ("Machine Super Intelligence", pdf)](http://www.vetta.org/documents/Machine_Super_Intelligence.pdf)
* [Collection of cool Deep Learning projects](http://deeplearninggallery.com)
* [Machine Learning projects from Stanfrod CS229](http://cs229.stanford.edu/projects2013.html)
